---
title: RAG란?
description:
author: Lee Yebin
date: 2025-12-06 11:33:00 +0800
categories: [연구실, 이론 정리]
tags: [RAG, LLM]
pin: false
math: true
mermaid: true
# image:
#   path: 
#   lqip: 
#   alt:
---

# RAG(Retrieval-Augmented Generation)

## 1. RAG란?

RAG는 **Retrieval-Augmented Generation**의 약자로, 한국어로는 **검색 증강 생성**이라고 번역한다. 단어를 하나씩 뜯어보면 그 의미가 명확해진다.

* **Retrieval (검색):** 외부의 신뢰할 수 있는 데이터베이스에서 관련 정보를 찾아온다.
* **Augmented (증강):** 찾아온 정보를 AI에게 제공하여 AI의 지식을 확장(보강)시킨다.
* **Generation (생성):** 보강된 정보를 바탕으로 AI가 답변을 생성한다.

한마디로 정의하자면, **"AI가 답변을 만들기 전에, 참고서를 먼저 찾아보고 그 내용을 바탕으로 대답하게 만드는 기술"** 이다.

* **일반적인 LLM (ChatGPT 등):** 공부한 내용을 머릿속에 암기해서 치르는 **'암기 테스트'** 다. 기억이 안 나거나 모르는 내용이 나오면 그럴듯하게 말을 지어내기도 한다.
* **RAG:** 교과서나 참고서를 펴놓고 시험을 치르는 **'오픈 북 테스트'** 다. 모르는 질문이 나오면 책을 찾아보고, 책에 적힌 정확한 내용을 바탕으로 답을 적는다.

## 2. 왜 RAG가 필요한가? (LLM의 한계)

GPT-4와 같은 최신 모델은 매우 똑똑하지만, 치명적인 단점 두 가지가 존재한다. RAG는 이 두 가지 문제를 해결하기 위해 등장했다.

### 2-1. 환각 현상 (Hallucination)
AI는 모르는 것도 아는 척 뻔뻔하게 거짓말을 할 때가 있다. 이를 '환각'이라고 한다. 예를 들어 "세종대왕의 맥북 프로 던짐 사건에 대해 알려줘"라고 물으면, AI가 마치 실존했던 역사인 것처럼 소설을 쓰는 현상이다. RAG는 "팩트(참고 자료)"를 먼저 쥐어주기 때문에 거짓말을 할 확률이 현저히 줄어든다.

### 2-2. 최신 정보의 부재와 데이터의 폐쇄성
AI 모델은 학습 시점(Cut-off) 이후의 일은 모른다. 또한, 우리 회사의 사내 매뉴얼이나 내 개인 일기장 같은 '비공개 데이터'는 학습하지 않았기에 알 수가 없다. RAG를 사용하면 AI를 재학습시키지 않고도, 외부 데이터를 실시간으로 참고하여 최신 정보나 비공개 정보를 답변할 수 있다.

## 3. RAG의 작동 원리와 과정 (Deep Dive)

RAG가 실제로 어떻게 작동하는지, 사용자가 질문을 던지는 순간부터 답변을 받는 순간까지의 과정을 단계별로 살펴보자. 크게 **데이터 준비(Indexing)** 단계와 **실제 사용(Retrieval & Generation)** 단계로 나뉜다.

### 3-1. 사전 준비: 데이터 색인 (Indexing)
AI가 참고할 '책(데이터)'을 도서관에 정리해 넣는 과정이다. 단순히 텍스트를 저장하는 것이 아니라 AI가 이해할 수 있는 형태로 변환해야 한다.

1.  **로드(Load):** PDF, 워드, 웹페이지 등 다양한 형식의 문서를 불러온다.
2.  **청킹(Chunking):** 긴 문서를 AI가 읽기 좋은 크기(문단, 페이지 등)로 잘게 쪼갠다. 너무 길면 정확도가 떨어지기 때문이다.
3.  **임베딩(Embedding):** 쪼개진 텍스트를 숫자의 나열인 '벡터(Vector)'로 변환한다. 컴퓨터는 글자보다 숫자로 의미를 파악하는 것이 빠르기 때문이다.
4.  **저장(Storing):** 변환된 벡터들을 '벡터 데이터베이스(Vector DB)'에 저장한다.

### 3-2. 검색 (Retrieval)
사용자가 질문을 던졌을 때 일어나는 과정이다.

1.  **질문 임베딩:** 사용자의 질문("우리 회사 연차 규정이 뭐야?")을 역시 벡터(숫자)로 변환한다.
2.  **유사도 검색:** 사용자의 질문 벡터와 가장 유사한 벡터를 가진 문서 조각을 벡터 DB에서 찾는다. 단순히 키워드 매칭이 아니라 의미적으로 가까운 내용을 찾아내는 것이다.

### 3-3. 생성 (Generation)
찾아낸 정보와 질문을 합쳐 AI에게 전달하는 과정이다.

1.  **프롬프트 작성:** 시스템은 AI에게 다음과 같은 명령어를 내부적으로 조합한다.
    > "사용자가 '{질문}'이라고 물어봤어. 내가 데이터베이스에서 찾은 이 '{검색된 문서 내용}'을 참고해서 답변해 줘. 만약 문서에 없으면 모른다고 해."
2.  **답변 생성:** LLM은 사용자의 질문뿐만 아니라 함께 제공된 '검색된 문서 내용'을 읽고, 이를 요약하거나 재구성하여 최종 답변을 생성한다.

## 4. RAG의 장점 정리

RAG를 도입했을 때 얻을 수 있는 이점은 명확하다.

* **정확성 향상:** 근거 없는 거짓말(환각)을 최소화하고, 팩트에 기반한 답변을 제공한다.
* **최신성 유지:** AI 모델을 매번 새로 학습시킬 필요 없이, 데이터베이스의 문서만 업데이트하면 언제나 최신 정보를 반영할 수 있다.
* **비용 절감:** LLM 자체를 파인 튜닝(Fine-tuning)하는 것보다 시스템 구축 비용이 훨씬 저렴하다.
* **출처 명시 가능:** 답변이 어떤 문서를 참고했는지 사용자에게 출처(Reference)를 함께 보여줄 수 있어 신뢰도가 높아진다.
