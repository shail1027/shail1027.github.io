---
title: "벡터 데이터베이스"
excerpt: "벡터 데이터베이스 정리"

categories:
  - 연구실
# tags:
#   - [tag1, tag2]

permalink: /DILAB/벡터-데이터베이스/

toc: true
toc_sticky: true

date: 2025-08-12
last_modified_at: 2025-08-12
---

## 1. Vector란?

> 벡터 = 데이터 의미를 담은 수치 표현

- 벡터는 **텍스트, 이미지, 오디오**처럼 AI가 이해할 수 없는 데이터를 기계가 연산할 수 있는 **숫자 리스트**로 표현한 것
- 데이터를 압축하여 가진 의미를 보존하고 있어, 의미적으로 비슷한 항목은 벡터 공간에서 가깝게 위치함
- 동일한 형식(벡터)으로, 텍스트/이미지/오디오 등 이질적 데이터 타입을 **한 공간에 올려 비교**할 수 있음

<img src="../assets/images/vectorDatabase/vector.jpg" />

### 1.1 벡터 임베딩이란?

> 임베딩이란, 텍스트/이미지 등을 의미를 보존하는 고차원 벡터로 변환한 결과이자 그 자체

- 임베딩 간 거리(혹은 유사도)가 원본 간 의미적 유사성과 상관관계를 갖도록 학습됨
- LLM/ML 모델이 직접 입력으로 사용하거나, 벡터 DB에 저장되어 시맨틱 검색/추천/RAG의 기반이 됨
    
<img src="../assets/images/vectorDatabase/embedding.jpg" />
    

### 1.2 벡터 임베딩 종류

1. **단어 임베딩 (Word Embedding)**
- 단어 하나를 의미 있는 숫자 벡터로 표현
- 대표 모델
    - **Word2Vec**: 주변 단어를 기반으로 단어 의미를 학습 (CBOW / Skip‑gram)
        
        → 예 : **king - man + woman ≈ queen**
        
    - **GloVe**: 단어 간 동시 출현 빈도(co-occurrence) 행렬 기반 학습
    - **FastText**: 단어 내부의 subword(n-gram) 요소까지 반영해 표현 → 어휘 외 단어에 강함

1. **문장 임베딩 (Sentence Embedding)**
- 문장 수준의 의미를 하나의 벡터로 표현
- 문장 간 유사도 계산, 검색 시스템, RAG 구조의 문맥 제공 등에 사용됨

1.  **문서 임베딩 (Document Embedding)**
- 보고서나 기사 같은 긴 문서 단위의 의미를 벡터로 압축
- 문서 추천, 클러스터링, 정보 검색, 문서 분류에 활용

1. **이미지 임베딩 (Image Embedding)**
- 이미지를 벡터로 변환해 의미 기반 비교
- CNN 기반 모델 (ResNet, VGG 등)을 통한 특징 추출
- 이미지 유사도 검색, 객체 인식, 추천 시스템에 활용됨

## 2. 벡터 데이터베이스란?

- 문서/이미지/오디오 같은 비정형 데이터를 임베딩 모델로 고차원 벡터로 바꿔 저장하고, **의미 유사성으로 검색**하는데 특화된 DB
    - 키워드 일치 대신 유사도를 기준으로 가장 가까운 K개를 찾아냄
- 백터 데이터베이스의 핵심
    1. **데이터 모델**: 각 레코드는 `id + vector + metadata`의 형태
        - **벡터**는 의미를 담은 고차원 수치(예: 384/768/1,536차원)
        - **메타데이터**는 태그·타임스탬프·권한 등 필터링에 쓰는 정형 값
            - 이 구조 덕분에 “유사도(벡터)”와 “조건(메타데이터)”를 함께 걸어 **정확도와 실용성**을 동시에 확보
    2. **유사도 기반 검색**: 코사인/내적/L2 같은 **거리(유사도) 함수**로 Top‑K 가까운 벡터를 되돌림. 
        - 제품마다 기본값이 다르지만 일반적으로 텍스트 임베딩은 코사인이 기본이며, 필요에 따라 내적 또는 L2를 선택
    3. **대규모 인덱싱**: 전수 스캔은 불가능하니 HNSW, IVF, PQ 같은 **근사 최근접 탐색(ANN)** 인덱스로 후보를 찾음
        - 속도·메모리·정확도 간의 트레이드오프가 설계의 핵심 요소
    - 최근에는 클라우드 벤더도 벡터 기능을 일제히 기본 제공(e.g. Azure Cosmos DB의 벡터, AWS의 여러 옵션)하면서, “기존 데이터와 벡터를 **한곳에서** 다루는” 패턴이 확산되는 중

## 3. 벡터 DB 작동 원리

<img src="../assets/images/vectorDatabase/pipeLine.jpg" />

### 3.1 파이프라인 개요

<aside>

**(1) 임베딩 생성 → (2) 저장/인덱싱 → (3) 질의 임베딩 → (4) ANN 검색(+필터) → (5) Top‑K 반환 → (6) 후처리(재랭킹·RAG 컨텍스트)** 의 순서로 동작

</aside>

- **임베딩 생성** : 같은 모델·전처리로 문서를 청크(보통 수백 토큰)로 나누고 임베딩한다. 쿼리도 동일 모델로 벡터화해야 검색 공간이 일치한다.
- **저장/인덱싱** : 벡터와 메타데이터를 함께 upsert하고, HNSW/IVF/PQ 등 인덱스를 빌드한다.
- **검색** : 질의 벡터로 ANN 인덱스를 탐색하면서 **메타데이터 필터**를 동시에 적용(엔진에 따라 그래프에 필터 엣지를 추가하거나, 필터 인덱스를 통합)하여 **정확한 후보**를 반환한다.
- **후처리** : 하이브리드 검색(키워드+벡터) 또는 재랭킹 모델을 얹어 결과를 안정화한다. RAG에선 Top‑K 내용을 LLM 입력 컨텍스트로 넣는다.

### 3.2 인덱스(ANN) 핵심

- **HNSW** : 다층 그래프를 따라 넓게→깊게 내려가며 근접점을 탐색.
    - 정확도/지연/메모리의 균형이 좋음(파라미터 `M`, `efConstruction`, `efSearch`가 품질·속도를 좌우)
        - https://www.pinecone.io/learn/series/faiss/hnsw/ (todo : 번역해서 정리하기)
- **IVF(역파일)** : 공간을 여러 클러스터(nlist)로 나누고, 검색 시 일부 클러스터만 조사(**nprobe**).
    - 빠르지만 클러스터 경계 밖의 최근접을 놓칠 수 있어 튜닝을 해야 함.
- **PQ(양자화)** : 벡터를 분할·코드북화해 **메모리·저장 비용**을 크게 줄임.
    - 보통 IVF와 결합(IVF‑PQ)해 대규모를 싼 비용으로 굴린다. 정밀도 손실을 줄이려면 **재정밀(Refine)** 단계로 원본 벡터를 재채점한다.

### 3.3 거리(유사도) 함수 선택

- **코사인** : 크기보다 **방향**이 중요할 때 적합(텍스트 임베딩 기본)
- **내적** : 크기·방향을 함께 반영. 정규화된 임베딩에서는 코사인과 동치가 됨
- **L2** : 좌표 거리. (모델 학습 목적이 L2 기반이면 나쁘지 않음)

## 4. 왜 중요할까?

1. **의미 기반 AI 기능의 필수 인프라**
- LLM 같은 생성 AI는 훈련 후에 업데이트된 정보에 접근하기 어렵고, 내부 지식에만 의존해 답하다 보면 **환각(hallucination)** 문제가 발생함
- 벡터 데이터베이스는 **내부 문서나 최신 데이터를 임베딩하여 저장**하고, 필요한 정보에 즉시 접근할 수 있게 해줘 AI 답변의 **정확성과 신뢰성**을 높임.
    - 이를 **RAG(Retrieval-Augmented Generation)** 구조라 부름

2. **복잡한 유사성 검색의 해결사**

- 텍스트, 이미지, 오디오 같은 **비정형 데이터를 의미 기반으로 비교**하는 것은 단순 키워드 매칭만으로는 어려움
- 벡터 DB는 **고차원 임베딩 벡터 공간**에서 의미적으로 가까운 항목들을 빠르게 찾을 수 있게 해주며, 이를 통해 보다 정교한 검색, 추천, 분류가 가능해짐

## 6. 참고

[Vector Database: What is it and why you should know it?](https://medium.com/@EjiroOnose/vector-database-what-is-it-and-why-you-should-know-it-ae7e7dca82a4)

[What Are Vector Databases? The Secret Sauce Behind AI and LLMs](https://medium.com/@tahirbalarabe2/what-are-vector-databases-the-secret-sauce-behind-ai-and-llms-62ff320a6843)

[Vector search - Azure AI Search](https://learn.microsoft.com/en-us/azure/search/vector-search-overview?utm_source=chatgpt.com)
